{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac453ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from mamba_ssm.models.config_mamba import MambaConfig\n",
    "from transformers import AutoTokenizer\n",
    "from model import MambaEmbedModel\n",
    "from mteb import MTEB\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457d4a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = MambaEmbedModel.from_pretrained(\"state-spaces/mamba-2.8b\", device=\"cuda\", dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f09fc287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb.tasks import CQADupstackAndroidRetrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8a56dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QuoraRetrieval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "084f6015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on QuoraRetrieval in module mteb.tasks.Retrieval.en.QuoraRetrieval object:\n",
      "\n",
      "class QuoraRetrieval(mteb.abstasks.AbsTaskRetrieval.AbsTaskRetrieval)\n",
      " |  QuoraRetrieval(**kwargs)\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      QuoraRetrieval\n",
      " |      mteb.abstasks.AbsTaskRetrieval.AbsTaskRetrieval\n",
      " |      mteb.abstasks.AbsTask.AbsTask\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  description\n",
      " |      Returns a description of the task. Should contain the following fields:\n",
      " |      name: Name of the task (usually equal to the class name. Should be a valid name for a path on disc)\n",
      " |      description: Longer description & references for the task\n",
      " |      type: Of the set: [sts]\n",
      " |      eval_splits: Splits used for evaluation as list, e.g. ['dev', 'test']\n",
      " |      main_score: Main score value for task\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from mteb.abstasks.AbsTaskRetrieval.AbsTaskRetrieval:\n",
      " |\n",
      " |  __init__(self, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  evaluate(self, model, split='test', **kwargs)\n",
      " |      Evaluates a Sentence Embedding Model on the task.\n",
      " |      Returns a dict (that can be serialized to json).\n",
      " |      :param model: Sentence embedding method. Implements a encode(sentences) method, that encodes sentences\n",
      " |      and returns a numpy matrix with the sentence embeddings\n",
      " |      :param split: Which datasplit to be used.\n",
      " |\n",
      " |  load_data(self, **kwargs)\n",
      " |      Load dataset from HuggingFace hub\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from mteb.abstasks.AbsTask.AbsTask:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "104bcf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator=MTEB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34695b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/jiatongy/mamba/MambaEmbed\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd771186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configs\t\t       exp.ipynb    model.py\t  mteb_output\t    results\r\n",
      "data_playground.ipynb  __init__.py  mteb_eval.py  playground.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81479ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "config_path = \"configs/mteb_tasks.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68996dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_path, 'r') as file:\n",
    "    mteb_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fe69a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_lst = []\n",
    "for task_category in mteb_config.values():\n",
    "        if task_category['select']:\n",
    "            task_lst.extend(task_category['task_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb1eaa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SprintDuplicateQuestions', 'TwitterSemEval2015', 'TwitterURLCorpus']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18f457f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56fcdfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donwlading SprintDuplicateQuestions...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'mteb.tasks' has no attribute 'SprintDuplicateQuestions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task_name \u001b[38;5;129;01min\u001b[39;00m task_lst:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdonwlading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     task_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtask_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     task \u001b[38;5;241m=\u001b[39m task_module\n\u001b[1;32m      6\u001b[0m     task\u001b[38;5;241m.\u001b[39mload_data()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mteb.tasks' has no attribute 'SprintDuplicateQuestions'"
     ]
    }
   ],
   "source": [
    "module = importlib.import_module(\"mteb.tasks\")\n",
    "for task_name in task_lst:\n",
    "    print(f\"donwlading {task_name}...\")\n",
    "    task_module = getattr(module,task_name)\n",
    "    task = task_module\n",
    "    task.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "216d4c6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mteb.tasks' has no attribute 'SprintDuplicateQuestions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSprintDuplicateQuestions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mteb.tasks' has no attribute 'SprintDuplicateQuestions'"
     ]
    }
   ],
   "source": [
    "getattr(module,\"SprintDuplicateQuestions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d59d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
